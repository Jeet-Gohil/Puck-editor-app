# ğŸ”„ Workflow Summary - AI Content Generation

## ğŸ“‹ **Quick Reference**

### **Complete Flow in 9 Steps**

```
1. User clicks "Generate with AI" button
   â†“
2. Frontend creates unique element ID: "HeroSectionOne-abc123_custom_navbarBrand"
   â†“
3. POST request to /api/generate-ai with element ID and field info
   â†“
4. API route calls AIService.generateFieldContent()
   â†“
5. AIService submits job to Python server: POST /generate
   â†“
6. AIService connects to SSE stream: GET /stream
   â†“
7. Python server processes job with OpenAI API
   â†“
8. Python server broadcasts result via SSE with EXACT element ID
   â†“
9. Frontend receives result, matches element ID, updates field
```

## ğŸ”§ **Key Files & Functions**

### **Frontend (TypeScript/React)**
- **`src/components/fields/EnhancedTextField.tsx`** â†’ `handleAIGenerate()` - Triggers AI generation
- **`src/app/api/generate-ai/route.ts`** â†’ `POST()` - API endpoint for AI requests
- **`src/utils/aiService.ts`** â†’ `makeAIRequest()` - SSE communication with Python server
- **`src/utils/aiDataHandler.ts`** â†’ `writeAIData()` - Persists generated content to JSON
- **`src/hooks/useAIDataWatcher.ts`** â†’ `useAIDataWatcher()` - Real-time data polling
- **`src/app/editor/page.tsx`** â†’ `handleAIResponse()` - Updates Puck editor data

### **Backend (Python/Flask)**
- **`test_sse_server.py`** â†’ `generate()` - Receives and queues AI jobs
- **`test_sse_server.py`** â†’ `worker_loop()` - Background job processing
- **`test_sse_server.py`** â†’ `run_openai_function_call()` - OpenAI API integration
- **`test_sse_server.py`** â†’ `broadcast()` - SSE message broadcasting
- **`test_sse_server.py`** â†’ `sse_stream()` - SSE endpoint for real-time updates

## ğŸ†” **Element ID System**

### **Format**: `{ComponentType}-{UUID}_custom_{fieldName}`

**Example**: `HeroSectionOne-abc123_custom_navbarBrand`

### **Critical Rule**: Element ID must remain EXACTLY the same throughout entire flow

```
Frontend generates: "HeroSectionOne-abc123_custom_navbarBrand"
                    â†“ (EXACT SAME)
API route receives: "HeroSectionOne-abc123_custom_navbarBrand"
                    â†“ (EXACT SAME)
Python processes:   "HeroSectionOne-abc123_custom_navbarBrand"
                    â†“ (OpenAI might change it!)
Python CORRECTS:    "HeroSectionOne-abc123_custom_navbarBrand"
                    â†“ (EXACT SAME)
Frontend matches:   "HeroSectionOne-abc123_custom_navbarBrand" âœ…
```

## ğŸ“¡ **SSE Communication**

### **Job Submission**
```http
POST http://localhost:8000/generate
Content-Type: application/json

{
  "elementid": "HeroSectionOne-abc123_custom_navbarBrand",
  "field": "navbarBrand",
  "business_description": "Modern web application",
  "prompt": "Generate a professional brand name..."
}
```

### **SSE Stream Connection**
```http
GET http://localhost:8000/stream
Accept: text/event-stream
Cache-Control: no-cache
```

### **SSE Response Format**
```
event: result
data: {"elementid": "HeroSectionOne-abc123_custom_navbarBrand", "output": "TechFlow Pro"}
```

## ğŸ’¾ **Data Storage**

### **AI Data Structure** (`data/ai-generated-content.json`)
```json
{
  "HeroSectionOne-abc123_custom_navbarBrand": {
    "navbarBrand": {
      "value": "TechFlow Pro",
      "timestamp": "2025-08-16T10:00:00.000Z",
      "generated": true,
      "fieldType": "text"
    }
  }
}
```

## ğŸ› **Common Issues & Solutions**

### **âŒ Values Going to Wrong Fields**
- **Cause**: Element ID mismatch
- **Solution**: Check console logs for "ğŸ” Comparing element IDs"
- **Fix**: Ensure Python server returns exact element ID

### **âŒ Timeout Errors**
- **Cause**: SSE connection not receiving results
- **Solution**: Check Python server logs for job processing
- **Debug**: Test `/stream` endpoint accessibility

### **âŒ No AI Generation**
- **Cause**: Python server not running or OpenAI API issues
- **Solution**: Check server console and API key
- **Debug**: Test `/test` endpoint for server health

## ğŸ” **Debug Commands**

### **Test SSE Server Health**
```bash
curl http://localhost:8000/test
```

### **Test SSE Stream**
```bash
curl http://localhost:8000/stream
```

### **Manual Test Broadcast**
```bash
curl -X POST http://localhost:8000/test-broadcast
```

## ğŸ“Š **Performance Metrics**

- **SSE Connection**: ~100ms setup time
- **OpenAI API Call**: 2-5 seconds average
- **Total Request Time**: 3-6 seconds typical
- **Timeout**: 45 seconds maximum
- **Polling Interval**: 2 seconds for data sync

## ğŸ¯ **Success Indicators**

### **Frontend Console Logs**
```
ğŸš€ Starting AI request for: HeroSectionOne-abc123_custom_navbarBrand navbarBrand
âœ… Job submitted successfully: {"ok": true, "queued": true}
ğŸ¯ Found result for our element: HeroSectionOne-abc123_custom_navbarBrand
ğŸ“ Output: TechFlow Pro
```

### **Python Server Console Logs**
```
ğŸ“¥ Queued job for HeroSectionOne-abc123_custom_navbarBrand, field: navbarBrand
ğŸš€ Processing job for element: HeroSectionOne-abc123_custom_navbarBrand
âœ… Generated content for HeroSectionOne-abc123_custom_navbarBrand in 2.5s: TechFlow Pro
```

## ğŸš€ **Quick Start Commands**

```bash
# 1. Start Python SSE Server
python test_sse_server.py

# 2. Start Frontend (new terminal)
npm run dev

# 3. Open Editor
# Navigate to: http://localhost:3000/editor

# 4. Test AI Generation
# Click any "Generate with AI" button in the editor
```

---

**For detailed technical implementation, see `TECHNICAL_DOCUMENTATION.md`**
